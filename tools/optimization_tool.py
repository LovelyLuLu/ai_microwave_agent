from __future__ import annotations
from pathlib import Path
from typing import Optional, Dict, Any, List, Union, Callable
from pydantic import BaseModel, Field
from langchain.tools import BaseTool
from datetime import datetime
import numpy as np
import json
import os
import random
import time
from abc import ABC, abstractmethod
from pyaedt import Hfss
from pyaedt.generic.general_methods import pyaedt_function_handler

# ---------- æ•°æ®ç»“æ„å®šä¹‰ ----------

class OptimizationVariable(BaseModel):
    """ä¼˜åŒ–å˜é‡å®šä¹‰"""
    name: str = Field(description="å˜é‡åç§°")
    min_value: float = Field(description="æœ€å°å€¼")
    max_value: float = Field(description="æœ€å¤§å€¼")
    initial_value: Optional[float] = Field(default=None, description="åˆå§‹å€¼ï¼ˆå¯é€‰ï¼‰")
    description: Optional[str] = Field(default="", description="å˜é‡æè¿°")

class OptimizationObjective(BaseModel):
    """ä¼˜åŒ–ç›®æ ‡å®šä¹‰"""
    name: str = Field(description="ç›®æ ‡åç§°")
    target_type: str = Field(description="ç›®æ ‡ç±»å‹ï¼šminimize, maximize, target")
    target_value: Optional[float] = Field(default=None, description="ç›®æ ‡å€¼ï¼ˆå½“target_typeä¸ºtargetæ—¶ä½¿ç”¨ï¼‰")
    weight: float = Field(default=1.0, description="æƒé‡")
    description: Optional[str] = Field(default="", description="ç›®æ ‡æè¿°")

class OptimizationParams(BaseModel):
    """ä¼˜åŒ–å‚æ•°ç»Ÿä¸€æ¥å£"""
    # ç®—æ³•é€‰æ‹©
    algorithm: str = Field(
        description="ä¼˜åŒ–ç®—æ³•ï¼šGAï¼ˆé—ä¼ ç®—æ³•ï¼‰æˆ–PSOï¼ˆç²’å­ç¾¤ç®—æ³•ï¼‰",
        default="GA"
    )
    
    # ä¼˜åŒ–å˜é‡
    variables: List[OptimizationVariable] = Field(
        description="ä¼˜åŒ–å˜é‡åˆ—è¡¨"
    )
    
    # ä¼˜åŒ–ç›®æ ‡
    objectives: List[OptimizationObjective] = Field(
        description="ä¼˜åŒ–ç›®æ ‡åˆ—è¡¨"
    )
    
    # é€šç”¨ç®—æ³•å‚æ•°
    population_size: int = Field(
        default=50,
        description="ç§ç¾¤å¤§å°",
        gt=0
    )
    max_iterations: int = Field(
        default=100,
        description="æœ€å¤§è¿­ä»£æ¬¡æ•°",
        gt=0
    )
    convergence_threshold: float = Field(
        default=1e-6,
        description="æ”¶æ•›é˜ˆå€¼"
    )
    
    # GAç‰¹æœ‰å‚æ•°
    crossover_rate: float = Field(
        default=0.8,
        description="äº¤å‰æ¦‚ç‡ï¼ˆGAï¼‰",
        ge=0.0,
        le=1.0
    )
    mutation_rate: float = Field(
        default=0.1,
        description="å˜å¼‚æ¦‚ç‡ï¼ˆGAï¼‰",
        ge=0.0,
        le=1.0
    )
    
    # PSOç‰¹æœ‰å‚æ•°
    inertia_weight: float = Field(
        default=0.9,
        description="æƒ¯æ€§æƒé‡ï¼ˆPSOï¼‰",
        ge=0.0,
        le=1.0
    )
    cognitive_coefficient: float = Field(
        default=2.0,
        description="è®¤çŸ¥ç³»æ•°ï¼ˆPSOï¼‰",
        gt=0.0
    )
    social_coefficient: float = Field(
        default=2.0,
        description="ç¤¾ä¼šç³»æ•°ï¼ˆPSOï¼‰",
        gt=0.0
    )
    
    # é¡¹ç›®ç›¸å…³
    project_name: Optional[str] = Field(
        default=None,
        description="é¡¹ç›®åç§°"
    )
    design_name: Optional[str] = Field(
        default=None,
        description="è®¾è®¡åç§°"
    )
    
    # ç»“æœä¿å­˜
    save_results: bool = Field(
        default=True,
        description="æ˜¯å¦ä¿å­˜ç»“æœ"
    )
    results_dir: str = Field(
        default="results",
        description="ç»“æœä¿å­˜ç›®å½•"
    )

class OptimizationResult(BaseModel):
    """ä¼˜åŒ–ç»“æœç»Ÿä¸€æ¥å£"""
    # åŸºæœ¬ä¿¡æ¯
    algorithm: str = Field(description="ä½¿ç”¨çš„ç®—æ³•")
    success: bool = Field(description="ä¼˜åŒ–æ˜¯å¦æˆåŠŸ")
    message: str = Field(description="ç»“æœæ¶ˆæ¯")
    
    # æœ€ä¼˜è§£
    best_solution: Dict[str, float] = Field(description="æœ€ä¼˜è§£å˜é‡å€¼")
    best_fitness: float = Field(description="æœ€ä¼˜é€‚åº”åº¦å€¼")
    
    # ä¼˜åŒ–è¿‡ç¨‹ä¿¡æ¯
    iterations_completed: int = Field(description="å®Œæˆçš„è¿­ä»£æ¬¡æ•°")
    convergence_achieved: bool = Field(description="æ˜¯å¦è¾¾åˆ°æ”¶æ•›")
    
    # å†å²è®°å½•
    convergence_history: List[float] = Field(description="æ”¶æ•›å†å²")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_evaluations: int = Field(description="æ€»è¯„ä¼°æ¬¡æ•°")
    execution_time: float = Field(description="æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰")
    
    # æ–‡ä»¶ä¿¡æ¯
    result_file: Optional[str] = Field(default=None, description="ç»“æœæ–‡ä»¶è·¯å¾„")
    
    # æ—¶é—´æˆ³
    timestamp: str = Field(description="ä¼˜åŒ–å®Œæˆæ—¶é—´")

# ---------- ä¼˜åŒ–ç®—æ³•åŸºç±» ----------

class BaseOptimizer(ABC):
    """ä¼˜åŒ–ç®—æ³•åŸºç±»"""
    
    def __init__(self, params: OptimizationParams):
        self.params = params
        self.variables = params.variables
        self.objectives = params.objectives
        self.population_size = params.population_size
        self.max_iterations = params.max_iterations
        self.convergence_threshold = params.convergence_threshold
        
        # åˆå§‹åŒ–å˜é‡è¾¹ç•Œ
        self.bounds = [(var.min_value, var.max_value) for var in self.variables]
        self.var_names = [var.name for var in self.variables]
        
        # å†å²è®°å½•
        self.convergence_history = []
        self.total_evaluations = 0
        
        # ä¼˜åŒ–è¿‡ç¨‹ç›‘æ§
        self.history = []
        self.best_fitness_history = []
        self.progress_callback = None
        
    def set_progress_callback(self, callback):
        """è®¾ç½®è¿›åº¦å›è°ƒå‡½æ•°"""
        self.progress_callback = callback
        
    def _log_progress(self, generation: int, best_fitness: float, best_solution: Dict[str, float]):
        """è®°å½•ä¼˜åŒ–è¿›åº¦"""
        progress_info = {
            "generation": generation,
            "best_fitness": best_fitness,
            "best_solution": best_solution.copy(),
            "timestamp": datetime.now().isoformat()
        }
        self.history.append(progress_info)
        self.best_fitness_history.append(best_fitness)
        
        if self.progress_callback:
            self.progress_callback(progress_info)
    
    @abstractmethod
    def optimize(self, objective_function: Callable) -> OptimizationResult:
        """æ‰§è¡Œä¼˜åŒ–"""
        pass
    
    def evaluate_fitness(self, solution: np.ndarray, objective_function: Callable) -> float:
        """è¯„ä¼°é€‚åº”åº¦"""
        self.total_evaluations += 1
        
        # å°†è§£è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        solution_dict = {name: value for name, value in zip(self.var_names, solution)}
        
        # è°ƒç”¨ç›®æ ‡å‡½æ•°
        try:
            objectives_values = objective_function(solution_dict)
            
            # è®¡ç®—ç»¼åˆé€‚åº”åº¦ï¼ˆå¤šç›®æ ‡åŠ æƒæ±‚å’Œï¼‰
            total_fitness = 0.0
            for i, obj in enumerate(self.objectives):
                obj_value = objectives_values.get(obj.name, 0.0)
                
                if obj.target_type == "minimize":
                    fitness_contribution = -obj_value * obj.weight
                elif obj.target_type == "maximize":
                    fitness_contribution = obj_value * obj.weight
                elif obj.target_type == "target":
                    # ç›®æ ‡å€¼ä¼˜åŒ–ï¼šè·ç¦»ç›®æ ‡å€¼è¶Šè¿‘è¶Šå¥½
                    fitness_contribution = -abs(obj_value - obj.target_value) * obj.weight
                else:
                    fitness_contribution = 0.0
                
                total_fitness += fitness_contribution
            
            return total_fitness
            
        except Exception as e:
            print(f"ç›®æ ‡å‡½æ•°è¯„ä¼°é”™è¯¯: {str(e)}")
            return float('-inf')  # è¿”å›æå°å€¼è¡¨ç¤ºæ— æ•ˆè§£
    
    def generate_random_solution(self) -> np.ndarray:
        """ç”Ÿæˆéšæœºè§£"""
        solution = np.zeros(len(self.variables))
        for i, (min_val, max_val) in enumerate(self.bounds):
            if self.variables[i].initial_value is not None:
                # å¦‚æœæœ‰åˆå§‹å€¼ï¼Œåœ¨å…¶é™„è¿‘ç”Ÿæˆ
                initial = self.variables[i].initial_value
                range_size = (max_val - min_val) * 0.1  # 10%çš„èŒƒå›´
                solution[i] = np.clip(
                    np.random.normal(initial, range_size/3),
                    min_val, max_val
                )
            else:
                solution[i] = np.random.uniform(min_val, max_val)
        return solution
    
    def clip_solution(self, solution: np.ndarray) -> np.ndarray:
        """å°†è§£é™åˆ¶åœ¨è¾¹ç•Œå†…"""
        clipped = np.zeros_like(solution)
        for i, (min_val, max_val) in enumerate(self.bounds):
            clipped[i] = np.clip(solution[i], min_val, max_val)
        return clipped

# ---------- é—ä¼ ç®—æ³•å®ç° ----------

class GeneticAlgorithm(BaseOptimizer):
    """é—ä¼ ç®—æ³•ä¼˜åŒ–å™¨"""
    
    def __init__(self, params: OptimizationParams):
        super().__init__(params)
        self.crossover_rate = params.crossover_rate
        self.mutation_rate = params.mutation_rate
    
    def optimize(self, objective_function: Callable) -> OptimizationResult:
        """æ‰§è¡Œé—ä¼ ç®—æ³•ä¼˜åŒ–"""
        start_time = datetime.now()
        
        # åˆå§‹åŒ–ç§ç¾¤
        population = np.array([self.generate_random_solution() for _ in range(self.population_size)])
        fitness_values = np.array([self.evaluate_fitness(ind, objective_function) for ind in population])
        
        # è®°å½•æœ€ä¼˜è§£
        best_idx = np.argmax(fitness_values)
        best_solution = population[best_idx].copy()
        best_fitness = fitness_values[best_idx]
        
        self.convergence_history.append(best_fitness)
        
        # è®°å½•åˆå§‹è¿›åº¦
        best_solution_dict = {name: value for name, value in zip(self.var_names, best_solution)}
        self._log_progress(0, best_fitness, best_solution_dict)
        
        # è¿­ä»£ä¼˜åŒ–
        for generation in range(self.max_iterations):
            # é€‰æ‹©
            selected_population = self._selection(population, fitness_values)
            
            # äº¤å‰å’Œå˜å¼‚
            new_population = []
            for i in range(0, self.population_size, 2):
                parent1 = selected_population[i]
                parent2 = selected_population[min(i+1, self.population_size-1)]
                
                # äº¤å‰
                if np.random.random() < self.crossover_rate:
                    child1, child2 = self._crossover(parent1, parent2)
                else:
                    child1, child2 = parent1.copy(), parent2.copy()
                
                # å˜å¼‚
                child1 = self._mutation(child1)
                child2 = self._mutation(child2)
                
                new_population.extend([child1, child2])
            
            # æ›´æ–°ç§ç¾¤
            population = np.array(new_population[:self.population_size])
            fitness_values = np.array([self.evaluate_fitness(ind, objective_function) for ind in population])
            
            # æ›´æ–°æœ€ä¼˜è§£
            current_best_idx = np.argmax(fitness_values)
            if fitness_values[current_best_idx] > best_fitness:
                best_solution = population[current_best_idx].copy()
                best_fitness = fitness_values[current_best_idx]
            
            self.convergence_history.append(best_fitness)
            
            # è®°å½•è¿›åº¦
            best_solution_dict = {name: value for name, value in zip(self.var_names, best_solution)}
            self._log_progress(generation + 1, best_fitness, best_solution_dict)
            
            # æ£€æŸ¥æ”¶æ•›
            if len(self.convergence_history) > 10:
                recent_improvement = abs(self.convergence_history[-1] - self.convergence_history[-10])
                if recent_improvement < self.convergence_threshold:
                    break
        
        # æ„å»ºç»“æœ
        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()
        
        best_solution_dict = {name: value for name, value in zip(self.var_names, best_solution)}
        
        result = OptimizationResult(
            algorithm="GA",
            success=True,
            message=f"é—ä¼ ç®—æ³•ä¼˜åŒ–å®Œæˆï¼Œå…±è¿›è¡Œ{generation+1}ä»£è¿›åŒ–",
            best_solution=best_solution_dict,
            best_fitness=best_fitness,
            iterations_completed=generation+1,
            convergence_achieved=recent_improvement < self.convergence_threshold if 'recent_improvement' in locals() else False,
            convergence_history=self.convergence_history,
            total_evaluations=self.total_evaluations,
            execution_time=execution_time,
            timestamp=end_time.strftime("%Y-%m-%d %H:%M:%S")
        )
        
        return result
    
    def _selection(self, population: np.ndarray, fitness_values: np.ndarray) -> np.ndarray:
        """é”¦æ ‡èµ›é€‰æ‹©"""
        selected = []
        tournament_size = 3
        
        for _ in range(self.population_size):
            # éšæœºé€‰æ‹©tournament_sizeä¸ªä¸ªä½“
            tournament_indices = np.random.choice(len(population), tournament_size, replace=False)
            tournament_fitness = fitness_values[tournament_indices]
            
            # é€‰æ‹©æœ€ä¼˜ä¸ªä½“
            winner_idx = tournament_indices[np.argmax(tournament_fitness)]
            selected.append(population[winner_idx].copy())
        
        return np.array(selected)
    
    def _crossover(self, parent1: np.ndarray, parent2: np.ndarray) -> tuple:
        """å•ç‚¹äº¤å‰"""
        crossover_point = np.random.randint(1, len(parent1))
        
        child1 = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])
        child2 = np.concatenate([parent2[:crossover_point], parent1[crossover_point:]])
        
        return self.clip_solution(child1), self.clip_solution(child2)
    
    def _mutation(self, individual: np.ndarray) -> np.ndarray:
        """é«˜æ–¯å˜å¼‚"""
        mutated = individual.copy()
        
        for i in range(len(individual)):
            if np.random.random() < self.mutation_rate:
                # é«˜æ–¯å˜å¼‚
                min_val, max_val = self.bounds[i]
                mutation_strength = (max_val - min_val) * 0.1  # 10%çš„å˜å¼‚å¼ºåº¦
                mutated[i] += np.random.normal(0, mutation_strength)
        
        return self.clip_solution(mutated)

# ---------- ç²’å­ç¾¤ç®—æ³•å®ç° ----------

class ParticleSwarmOptimization(BaseOptimizer):
    """ç²’å­ç¾¤ä¼˜åŒ–ç®—æ³•"""
    
    def __init__(self, params: OptimizationParams):
        super().__init__(params)
        self.inertia_weight = params.inertia_weight
        self.cognitive_coefficient = params.cognitive_coefficient
        self.social_coefficient = params.social_coefficient
    
    def optimize(self, objective_function: Callable) -> OptimizationResult:
        """æ‰§è¡Œç²’å­ç¾¤ä¼˜åŒ–"""
        start_time = datetime.now()
        
        # åˆå§‹åŒ–ç²’å­ç¾¤
        particles = np.array([self.generate_random_solution() for _ in range(self.population_size)])
        velocities = np.zeros_like(particles)
        
        # è®°å½•ä¸ªä½“æœ€ä¼˜å’Œå…¨å±€æœ€ä¼˜
        personal_best_positions = particles.copy()
        personal_best_fitness = np.array([self.evaluate_fitness(p, objective_function) for p in particles])
        
        global_best_idx = np.argmax(personal_best_fitness)
        global_best_position = particles[global_best_idx].copy()
        global_best_fitness = personal_best_fitness[global_best_idx]
        
        self.convergence_history.append(global_best_fitness)
        
        # è®°å½•åˆå§‹è¿›åº¦
        best_solution_dict = {name: value for name, value in zip(self.var_names, global_best_position)}
        self._log_progress(0, global_best_fitness, best_solution_dict)
        
        # è¿­ä»£ä¼˜åŒ–
        for iteration in range(self.max_iterations):
            for i in range(self.population_size):
                # æ›´æ–°é€Ÿåº¦
                r1, r2 = np.random.random(2)
                
                cognitive_component = self.cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])
                social_component = self.social_coefficient * r2 * (global_best_position - particles[i])
                
                velocities[i] = (self.inertia_weight * velocities[i] + 
                               cognitive_component + social_component)
                
                # æ›´æ–°ä½ç½®
                particles[i] = particles[i] + velocities[i]
                particles[i] = self.clip_solution(particles[i])
                
                # è¯„ä¼°é€‚åº”åº¦
                current_fitness = self.evaluate_fitness(particles[i], objective_function)
                
                # æ›´æ–°ä¸ªä½“æœ€ä¼˜
                if current_fitness > personal_best_fitness[i]:
                    personal_best_positions[i] = particles[i].copy()
                    personal_best_fitness[i] = current_fitness
                    
                    # æ›´æ–°å…¨å±€æœ€ä¼˜
                    if current_fitness > global_best_fitness:
                        global_best_position = particles[i].copy()
                        global_best_fitness = current_fitness
            
            self.convergence_history.append(global_best_fitness)
            
            # è®°å½•è¿›åº¦
            best_solution_dict = {name: value for name, value in zip(self.var_names, global_best_position)}
            self._log_progress(iteration + 1, global_best_fitness, best_solution_dict)
            
            # æ£€æŸ¥æ”¶æ•›
            if len(self.convergence_history) > 10:
                recent_improvement = abs(self.convergence_history[-1] - self.convergence_history[-10])
                if recent_improvement < self.convergence_threshold:
                    break
        
        # æ„å»ºç»“æœ
        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()
        
        best_solution_dict = {name: value for name, value in zip(self.var_names, global_best_position)}
        
        result = OptimizationResult(
            algorithm="PSO",
            success=True,
            message=f"ç²’å­ç¾¤ä¼˜åŒ–å®Œæˆï¼Œå…±è¿›è¡Œ{iteration+1}æ¬¡è¿­ä»£",
            best_solution=best_solution_dict,
            best_fitness=global_best_fitness,
            iterations_completed=iteration+1,
            convergence_achieved=recent_improvement < self.convergence_threshold if 'recent_improvement' in locals() else False,
            convergence_history=self.convergence_history,
            total_evaluations=self.total_evaluations,
            execution_time=execution_time,
            timestamp=end_time.strftime("%Y-%m-%d %H:%M:%S")
        )
        
        return result

# ---------- ä¼˜åŒ–å·¥å…·ç±» ----------

class OptimizationTool(BaseTool):
    """ç»Ÿä¸€ä¼˜åŒ–å·¥å…·"""
    
    name: str = "optimization_tool"
    description: str = """å¾®æ³¢å™¨ä»¶è®¾è®¡ä¼˜åŒ–å·¥å…·ï¼Œæ”¯æŒé—ä¼ ç®—æ³•(GA)å’Œç²’å­ç¾¤ä¼˜åŒ–(PSO)ç®—æ³•ã€‚
    
    **åŠŸèƒ½ç‰¹ç‚¹**ï¼š
    - æ”¯æŒå¤šå˜é‡ã€å¤šç›®æ ‡ä¼˜åŒ–
    - æä¾›GAå’ŒPSOä¸¤ç§ä¼˜åŒ–ç®—æ³•
    - è‡ªåŠ¨ä¿å­˜ä¼˜åŒ–ç»“æœå’Œæ”¶æ•›å†å²
    - æ”¯æŒç›®æ ‡å‡½æ•°çš„æœ€å°åŒ–ã€æœ€å¤§åŒ–å’Œç›®æ ‡å€¼ä¼˜åŒ–
    
    **è¾“å…¥å‚æ•°**ï¼š
    - algorithm: ä¼˜åŒ–ç®—æ³•ï¼ˆ"GA"æˆ–"PSO"ï¼‰
    - variables: ä¼˜åŒ–å˜é‡åˆ—è¡¨ï¼Œæ¯ä¸ªå˜é‡åŒ…å«nameã€min_valueã€max_valueç­‰
    - objectives: ä¼˜åŒ–ç›®æ ‡åˆ—è¡¨ï¼Œæ¯ä¸ªç›®æ ‡åŒ…å«nameã€target_typeã€weightç­‰
    - population_size: ç§ç¾¤å¤§å°ï¼ˆé»˜è®¤50ï¼‰
    - max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤100ï¼‰
    - å…¶ä»–ç®—æ³•ç‰¹å®šå‚æ•°
    
    **ä½¿ç”¨ç¤ºä¾‹**ï¼š
    é€‚ç”¨äºæ»¤æ³¢å™¨ã€å¤©çº¿ã€è€¦åˆå™¨ç­‰å¾®æ³¢å™¨ä»¶çš„å‚æ•°ä¼˜åŒ–ï¼Œå¦‚ä¼˜åŒ–Så‚æ•°ã€VSWRã€å¸¦å®½ç­‰æ€§èƒ½æŒ‡æ ‡ã€‚
    """
    
    args_schema: type = OptimizationParams
    
    def _run(self, **kwargs) -> str:
        """æ‰§è¡Œä¼˜åŒ–"""
        try:
            # å¤„ç†LangChainä¼ é€’çš„å‚æ•°
            if 'kwargs' in kwargs:
                actual_kwargs = kwargs['kwargs']
            else:
                actual_kwargs = kwargs
            
            # è§£æå‚æ•°
            params = OptimizationParams(**actual_kwargs)
            
            # éªŒè¯å‚æ•°
            if not params.variables:
                return "é”™è¯¯ï¼šæœªå®šä¹‰ä¼˜åŒ–å˜é‡"
            
            if not params.objectives:
                return "é”™è¯¯ï¼šæœªå®šä¹‰ä¼˜åŒ–ç›®æ ‡"
            
            # åˆ›å»ºä¼˜åŒ–å™¨
            if params.algorithm.upper() == "GA":
                optimizer = GeneticAlgorithm(params)
            elif params.algorithm.upper() == "PSO":
                optimizer = ParticleSwarmOptimization(params)
            else:
                return f"é”™è¯¯ï¼šä¸æ”¯æŒçš„ä¼˜åŒ–ç®—æ³• '{params.algorithm}'ã€‚æ”¯æŒçš„ç®—æ³•ï¼šGA, PSO"
            
            # è®¾ç½®è¿›åº¦ç›‘æ§å›è°ƒ
            def progress_callback(progress_info):
                generation = progress_info['generation']
                best_fitness = progress_info['best_fitness']
                print(f"ç¬¬ {generation} ä»£: æœ€ä¼˜é€‚åº”åº¦ = {best_fitness:.6f}")
                
                # æ¯10ä»£æ˜¾ç¤ºä¸€æ¬¡æœ€ä¼˜è§£
                if generation % 10 == 0 and generation > 0:
                    print(f"  å½“å‰æœ€ä¼˜è§£: {progress_info['best_solution']}")
            
            optimizer.set_progress_callback(progress_callback)
            
            print(f"å¼€å§‹æ‰§è¡Œ {params.algorithm} ä¼˜åŒ–...")
            print(f"ç§ç¾¤å¤§å°: {params.population_size}, æœ€å¤§è¿­ä»£æ¬¡æ•°: {params.max_iterations}")
            
            # å®šä¹‰çœŸå®çš„HFSSä»¿çœŸç›®æ ‡å‡½æ•°
            def hfss_objective_function(solution_dict: Dict[str, float]) -> Dict[str, float]:
                """çœŸå®çš„HFSSä»¿çœŸç›®æ ‡å‡½æ•°è¯„ä¼°"""
                try:
                    # æŸ¥æ‰¾æœ€æ–°çš„HFSSé¡¹ç›®
                    project_path = self._find_latest_hfss_project()
                    if not project_path:
                        raise Exception("æœªæ‰¾åˆ°HFSSé¡¹ç›®æ–‡ä»¶")
                    
                    # è¿æ¥åˆ°HFSSé¡¹ç›®å¹¶æ›´æ–°å‚æ•°
                    hfss = None
                    try:
                        hfss = Hfss(project=project_path, non_graphical=True, new_desktop=False)
                        
                        # æ›´æ–°è®¾è®¡å‚æ•°
                        for param_name, param_value in solution_dict.items():
                            if param_name in hfss.variable_manager.variables:
                                hfss[param_name] = f"{param_value}mm"
                        
                        # è¿è¡Œä»¿çœŸ
                        setup_name = "MainSetup"
                        if setup_name in [s.name for s in hfss.setups]:
                            setup = hfss.get_setup(setup_name)
                            setup.analyze()
                        
                        # æå–Så‚æ•°æ•°æ®
                        sweep_name = "BroadbandSweep"
                        solution_data = hfss.post.get_solution_data(
                            expressions=["S(1,1)", "S(2,1)"],
                            setup_sweep_name=f"{setup_name} : {sweep_name}"
                        )
                        
                        if solution_data:
                            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                            freq = np.array(solution_data.primary_sweep_values)
                            s11_real = np.array(solution_data.data_real("S(1,1)"))
                            s11_imag = np.array(solution_data.data_imag("S(1,1)"))
                            s21_real = np.array(solution_data.data_real("S(2,1)"))
                            s21_imag = np.array(solution_data.data_imag("S(2,1)"))
                            
                            # è®¡ç®—å¹…åº¦ï¼ˆdBï¼‰
                            s11_mag = 20 * np.log10(np.sqrt(s11_real**2 + s11_imag**2))
                            s21_mag = 20 * np.log10(np.sqrt(s21_real**2 + s21_imag**2))
                            
                            # è®¡ç®—VSWR
                            s11_linear = np.sqrt(s11_real**2 + s11_imag**2)
                            vswr = (1 + s11_linear) / (1 - s11_linear + 1e-12)
                            
                            # è®¡ç®—ç›®æ ‡å€¼ï¼ˆåœ¨å·¥ä½œé¢‘æ®µå†…ï¼‰
                            work_band_mask = (freq >= 2.0e9) & (freq <= 8.0e9)  # 2-8 GHzå·¥ä½œé¢‘æ®µ
                            
                            # S21ç›®æ ‡ï¼šé€šå¸¦å†…æ’å…¥æŸè€—æœ€å°ï¼ˆè¶Šæ¥è¿‘0dBè¶Šå¥½ï¼‰
                            s21_target = -np.mean(np.abs(s21_mag[work_band_mask]))
                            
                            # S11ç›®æ ‡ï¼šå›æ³¢æŸè€—æœ€å¤§ï¼ˆè¶Šè´Ÿè¶Šå¥½ï¼‰
                            s11_target = np.mean(s11_mag[work_band_mask])
                            
                            # VSWRç›®æ ‡ï¼šæœ€å°åŒ–
                            vswr_target = np.mean(vswr[work_band_mask])
                            
                            return {
                                "S21": float(s21_target),
                                "S11": float(s11_target), 
                                "VSWR": float(vswr_target)
                            }
                        else:
                            raise Exception("æ— æ³•è·å–ä»¿çœŸæ•°æ®")
                            
                    finally:
                        if hfss:
                            hfss.close_project()
                            
                except Exception as e:
                    print(f"HFSSä»¿çœŸè¯„ä¼°å¤±è´¥: {e}")
                    # è¿”å›æƒ©ç½šå€¼
                    return {
                        "S21": -100.0,
                        "S11": 0.0,
                        "VSWR": 10.0
                    }
            
            # éªŒè¯HFSSé¡¹ç›®æ˜¯å¦å­˜åœ¨
            project_path = self._find_latest_hfss_project()
            if not project_path:
                return "âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°HFSSé¡¹ç›®æ–‡ä»¶ï¼Œè¯·å…ˆåˆ›å»ºå¹¶ä»¿çœŸä¸€ä¸ªHFSSé¡¹ç›®"
            
            print(f"æ‰¾åˆ°HFSSé¡¹ç›®: {project_path}")
            
            # æ‰§è¡Œä¼˜åŒ–
            result = optimizer.optimize(hfss_objective_function)
            
            # ä¿å­˜ç»“æœ
            if params.save_results:
                result_file = self._save_results(result, params)
                result.result_file = result_file
            
            # æ ¼å¼åŒ–è¿”å›æ¶ˆæ¯
            return self._format_result_message(result)
            
        except Exception as e:
            return f"ä¼˜åŒ–æ‰§è¡Œé”™è¯¯: {str(e)}"
    
    async def _arun(self, **kwargs) -> str:
        """å¼‚æ­¥æ‰§è¡Œï¼ˆè°ƒç”¨åŒæ­¥æ–¹æ³•ï¼‰"""
        return self._run(**kwargs)
    
    def _save_results(self, result: OptimizationResult, params: OptimizationParams) -> str:
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        try:
            # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
            results_dir = Path(params.results_dir)
            results_dir.mkdir(exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"optimization_result_{result.algorithm.lower()}_{timestamp}.json"
            filepath = results_dir / filename
            
            # ä¿å­˜ç»“æœ
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(result.dict(), f, ensure_ascii=False, indent=2)
            
            # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
            self._generate_detailed_report(result, params, results_dir, timestamp)
            
            print(f"ä¼˜åŒ–ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
            return str(filepath)
            
        except Exception as e:
            print(f"ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")
            return ""
    
    def _generate_detailed_report(self, result: OptimizationResult, params: OptimizationParams, results_dir: Path, timestamp: str):
        """ç”Ÿæˆè¯¦ç»†çš„ä¼˜åŒ–æŠ¥å‘Š"""
        try:
            report_filename = f"optimization_report_{result.algorithm.lower()}_{timestamp}.md"
            report_filepath = results_dir / report_filename
            
            with open(report_filepath, 'w', encoding='utf-8') as f:
                f.write(f"# ä¼˜åŒ–æŠ¥å‘Š - {result.algorithm}\n\n")
                f.write(f"**ç”Ÿæˆæ—¶é—´**: {result.timestamp}\n\n")
                
                # ä¼˜åŒ–é…ç½®
                f.write("## ä¼˜åŒ–é…ç½®\n\n")
                f.write(f"- **ç®—æ³•**: {result.algorithm}\n")
                f.write(f"- **ç§ç¾¤å¤§å°**: {params.population_size}\n")
                f.write(f"- **æœ€å¤§è¿­ä»£æ¬¡æ•°**: {params.max_iterations}\n")
                f.write(f"- **æ”¶æ•›é˜ˆå€¼**: {params.convergence_threshold}\n\n")
                
                # ä¼˜åŒ–å˜é‡
                f.write("## ä¼˜åŒ–å˜é‡\n\n")
                f.write("| å˜é‡å | æœ€å°å€¼ | æœ€å¤§å€¼ | åˆå§‹å€¼ | æè¿° |\n")
                f.write("|--------|--------|--------|--------|------|\n")
                for var in params.variables:
                    initial = var.initial_value if var.initial_value is not None else "N/A"
                    f.write(f"| {var.name} | {var.min_value} | {var.max_value} | {initial} | {var.description} |\n")
                f.write("\n")
                
                # ä¼˜åŒ–ç›®æ ‡
                f.write("## ä¼˜åŒ–ç›®æ ‡\n\n")
                f.write("| ç›®æ ‡å | ç±»å‹ | ç›®æ ‡å€¼ | æƒé‡ | æè¿° |\n")
                f.write("|--------|------|--------|------|------|\n")
                for obj in params.objectives:
                    target = obj.target_value if obj.target_value is not None else "N/A"
                    f.write(f"| {obj.name} | {obj.target_type} | {target} | {obj.weight} | {obj.description} |\n")
                f.write("\n")
                
                # ä¼˜åŒ–ç»“æœ
                f.write("## ä¼˜åŒ–ç»“æœ\n\n")
                f.write(f"- **çŠ¶æ€**: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}\n")
                f.write(f"- **è¿­ä»£æ¬¡æ•°**: {result.iterations_completed}\n")
                f.write(f"- **æ”¶æ•›çŠ¶æ€**: {'å·²æ”¶æ•›' if result.convergence_achieved else 'æœªå®Œå…¨æ”¶æ•›'}\n")
                f.write(f"- **æ‰§è¡Œæ—¶é—´**: {result.execution_time:.2f}ç§’\n")
                f.write(f"- **æ€»è¯„ä¼°æ¬¡æ•°**: {result.total_evaluations}\n")
                f.write(f"- **æœ€ä¼˜é€‚åº”åº¦**: {result.best_fitness:.6f}\n\n")
                
                # æœ€ä¼˜è§£
                f.write("## æœ€ä¼˜è§£\n\n")
                f.write("| å˜é‡å | æœ€ä¼˜å€¼ |\n")
                f.write("|--------|--------|\n")
                for var_name, var_value in result.best_solution.items():
                    f.write(f"| {var_name} | {var_value:.6f} |\n")
                f.write("\n")
                
                # æ”¶æ•›å†å²
                f.write("## æ”¶æ•›å†å²\n\n")
                f.write("```\n")
                for i, fitness in enumerate(result.convergence_history):
                    f.write(f"Generation {i}: {fitness:.6f}\n")
                f.write("```\n")
            
            print(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filepath}")
            
        except Exception as e:
            print(f"ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šå¤±è´¥: {str(e)}")
    
    def _find_latest_hfss_project(self) -> Optional[str]:
        """æŸ¥æ‰¾æœ€æ–°çš„HFSSé¡¹ç›®æ–‡ä»¶"""
        try:
            # åœ¨å½“å‰ç›®å½•å’Œå­ç›®å½•ä¸­æŸ¥æ‰¾.aedtæ–‡ä»¶
            current_dir = Path.cwd()
            aedt_files = list(current_dir.rglob("*.aedt"))
            
            if not aedt_files:
                return None
            
            # è¿”å›æœ€æ–°ä¿®æ”¹çš„é¡¹ç›®æ–‡ä»¶
            latest_file = max(aedt_files, key=lambda f: f.stat().st_mtime)
            return str(latest_file)
            
        except Exception as e:
            print(f"æŸ¥æ‰¾HFSSé¡¹ç›®æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def _format_result_message(self, result: OptimizationResult) -> str:
        """æ ¼å¼åŒ–ç»“æœæ¶ˆæ¯"""
        message = f"""ğŸ¯ {result.algorithm}ä¼˜åŒ–å®Œæˆï¼

ğŸ“Š **ä¼˜åŒ–ç»“æœ**ï¼š
- ç®—æ³•ï¼š{result.algorithm}
- çŠ¶æ€ï¼š{'âœ… æˆåŠŸ' if result.success else 'âŒ å¤±è´¥'}
- è¿­ä»£æ¬¡æ•°ï¼š{result.iterations_completed}/{result.iterations_completed}
- æ”¶æ•›çŠ¶æ€ï¼š{'âœ… å·²æ”¶æ•›' if result.convergence_achieved else 'â³ æœªå®Œå…¨æ”¶æ•›'}
- æ‰§è¡Œæ—¶é—´ï¼š{result.execution_time:.2f}ç§’
- æ€»è¯„ä¼°æ¬¡æ•°ï¼š{result.total_evaluations}

ğŸ† **æœ€ä¼˜è§£**ï¼š
"""
        
        for var_name, var_value in result.best_solution.items():
            message += f"- {var_name}: {var_value:.6f}\n"
        
        message += f"\nğŸ“ˆ **æœ€ä¼˜é€‚åº”åº¦**: {result.best_fitness:.6f}\n"
        
        if result.result_file:
            message += f"\nğŸ’¾ **ç»“æœæ–‡ä»¶**: {result.result_file}\n"
            message += f"ğŸ“‹ **è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆ**ï¼ŒåŒ…å«å®Œæ•´çš„ä¼˜åŒ–å†å²å’Œåˆ†æ\n"
        
        message += f"\nâ° **å®Œæˆæ—¶é—´**: {result.timestamp}"
        
        return message

# åˆ›å»ºå·¥å…·å®ä¾‹
OPTIMIZE_DESIGN = OptimizationTool()